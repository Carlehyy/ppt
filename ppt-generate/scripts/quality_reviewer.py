#!/usr/bin/env python3
"""
Quality Reviewer Module â€” å…¨å±€æ ¡å®¡ä¸è´¨é‡ä¿éšœä½“ç³»
PRDè¦æ±‚ï¼ˆäº”ç»´åº¦è¯„ä¼°ï¼‰ï¼š
1. å†…å®¹å‡†ç¡®æ€§ â€” æ•°æ®æº¯æºéªŒè¯ï¼Œæœç»å¹»è§‰
2. é€»è¾‘è¿è´¯æ€§ â€” ç« èŠ‚é—´è¿‡æ¸¡è‡ªç„¶ï¼Œå™äº‹çº¿å®Œæ•´
3. è§†è§‰è§„èŒƒæ€§ â€” ç‰ˆå¼ä½¿ç”¨æ­£ç¡®ï¼Œé£æ ¼ä¸€è‡´
4. ä¿¡æ¯å¯†åº¦ â€” æ¯é¡µä¿¡æ¯é‡é€‚ä¸­ï¼Œä¸è¿‡è½½ä¸ç©ºæ´
5. å—ä¼—é€‚é…æ€§ â€” è¯­è¨€ã€æ·±åº¦ã€ä¾§é‡ç‚¹åŒ¹é…ç›®æ ‡å—ä¼—
"""

import json
from typing import Dict, Any, List, Optional


class QualityReviewer:
    """è´¨é‡æ ¡å®¡å™¨"""

    def __init__(self, llm_client=None):
        self.llm_client = llm_client

    def review(self, slides_data: List[Dict], outline: Dict,
               parsed_content: Dict, template_analysis: Dict,
               final_config: Dict) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„è´¨é‡æ ¡å®¡

        Returns:
            {
                "overall_score": int,           # æ€»åˆ† 0-100
                "dimension_scores": {},         # äº”ç»´åº¦è¯„åˆ†
                "issues": [],                   # å‘ç°çš„é—®é¢˜
                "suggestions": [],              # æ”¹è¿›å»ºè®®
                "passed": bool,                 # æ˜¯å¦é€šè¿‡
                "summary": str,                 # æ€»ç»“æ–‡æœ¬
            }
        """
        print("  [æ ¡å®¡] å¼€å§‹äº”ç»´åº¦è´¨é‡è¯„ä¼°...")

        # ç»´åº¦1: å†…å®¹å‡†ç¡®æ€§
        print("  [æ ¡å®¡] ç»´åº¦1: å†…å®¹å‡†ç¡®æ€§...")
        accuracy = self._check_content_accuracy(slides_data, parsed_content)

        # ç»´åº¦2: é€»è¾‘è¿è´¯æ€§
        print("  [æ ¡å®¡] ç»´åº¦2: é€»è¾‘è¿è´¯æ€§...")
        coherence = self._check_logical_coherence(slides_data, outline)

        # ç»´åº¦3: è§†è§‰è§„èŒƒæ€§
        print("  [æ ¡å®¡] ç»´åº¦3: è§†è§‰è§„èŒƒæ€§...")
        visual = self._check_visual_compliance(slides_data, template_analysis)

        # ç»´åº¦4: ä¿¡æ¯å¯†åº¦
        print("  [æ ¡å®¡] ç»´åº¦4: ä¿¡æ¯å¯†åº¦...")
        density = self._check_information_density(slides_data)

        # ç»´åº¦5: å—ä¼—é€‚é…æ€§
        print("  [æ ¡å®¡] ç»´åº¦5: å—ä¼—é€‚é…æ€§...")
        audience = self._check_audience_fit(slides_data, final_config)

        # æ±‡æ€»
        dimension_scores = {
            "content_accuracy": accuracy,
            "logical_coherence": coherence,
            "visual_compliance": visual,
            "information_density": density,
            "audience_fit": audience,
        }

        # åŠ æƒè®¡ç®—æ€»åˆ†
        weights = {
            "content_accuracy": 0.30,
            "logical_coherence": 0.25,
            "visual_compliance": 0.15,
            "information_density": 0.15,
            "audience_fit": 0.15,
        }
        overall_score = sum(
            d.get("score", 0) * weights.get(k, 0.2)
            for k, d in dimension_scores.items()
        )
        overall_score = round(overall_score)

        # æ”¶é›†æ‰€æœ‰é—®é¢˜å’Œå»ºè®®
        all_issues = []
        all_suggestions = []
        for d in dimension_scores.values():
            all_issues.extend(d.get("issues", []))
            all_suggestions.extend(d.get("suggestions", []))

        # å¦‚æœLLMå¯ç”¨ï¼Œç”Ÿæˆç»¼åˆè¯„å®¡æ„è§
        summary = self._generate_review_summary(
            overall_score, dimension_scores, all_issues, all_suggestions, final_config
        )

        passed = overall_score >= 70 and not any(
            i.get("severity") == "critical" for i in all_issues
        )

        print(f"  [æ ¡å®¡] âœ“ æ€»åˆ†: {overall_score}/100 {'(é€šè¿‡)' if passed else '(æœªé€šè¿‡)'}")

        return {
            "overall_score": overall_score,
            "dimension_scores": dimension_scores,
            "issues": all_issues,
            "suggestions": all_suggestions,
            "passed": passed,
            "summary": summary,
        }

    def _check_content_accuracy(self, slides_data: List[Dict],
                                 parsed_content: Dict) -> Dict:
        """ç»´åº¦1: å†…å®¹å‡†ç¡®æ€§æ£€æŸ¥"""
        issues = []
        suggestions = []
        score = 100

        semantic_units = parsed_content.get("semantic_units", [])
        original_data = {}
        for unit in semantic_units:
            for kd in unit.get("key_data", []):
                original_data[kd.get("label", "")] = kd.get("value", "")

        for sd in slides_data:
            if sd.get("status") == "failed":
                issues.append({
                    "dimension": "content_accuracy",
                    "severity": "critical",
                    "page": sd.get("page_num"),
                    "message": f"ç¬¬{sd.get('page_num')}é¡µç”Ÿæˆå¤±è´¥",
                })
                score -= 15
                continue

            content = sd.get("content", {})
            source_info = content.get("source_info", [])

            # æ£€æŸ¥æ˜¯å¦æœ‰ä½ç½®ä¿¡åº¦å†…å®¹
            low_conf = [s for s in source_info if s.get("confidence") == "low"]
            if low_conf:
                issues.append({
                    "dimension": "content_accuracy",
                    "severity": "warning",
                    "page": sd.get("page_num"),
                    "message": f"ç¬¬{sd.get('page_num')}é¡µæœ‰{len(low_conf)}æ¡ä½ç½®ä¿¡åº¦å†…å®¹",
                    "details": [lc.get("content", "")[:30] for lc in low_conf],
                })
                score -= 3 * len(low_conf)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ— æ¥æºçš„å†…å®¹
            body = content.get("body", [])
            if body and not source_info:
                if sd.get("content_type") not in ("cover", "ending", "section_divider"):
                    issues.append({
                        "dimension": "content_accuracy",
                        "severity": "info",
                        "page": sd.get("page_num"),
                        "message": f"ç¬¬{sd.get('page_num')}é¡µå†…å®¹ç¼ºå°‘æ¥æºæ ‡æ³¨",
                    })
                    score -= 2

        # æ£€æŸ¥must_showå†…å®¹è¦†ç›–
        must_show = [u for u in semantic_units if u.get("granularity") == "must_show"]
        all_body_text = " ".join(
            " ".join(sd.get("content", {}).get("body", []))
            for sd in slides_data
        )
        uncovered = 0
        for unit in must_show:
            content_text = unit.get("content", "")
            if content_text[:15] not in all_body_text and content_text[-15:] not in all_body_text:
                uncovered += 1

        if must_show and uncovered > 0:
            coverage = 1 - uncovered / len(must_show)
            if coverage < 0.8:
                issues.append({
                    "dimension": "content_accuracy",
                    "severity": "warning",
                    "message": f"å¿…é¡»å‘ˆç°å†…å®¹è¦†ç›–ç‡: {coverage:.0%} ({uncovered}é¡¹æœªè¦†ç›–)",
                })
                score -= int((1 - coverage) * 30)

        score = max(0, min(100, score))
        if score < 80:
            suggestions.append("å»ºè®®æ£€æŸ¥ä½ç½®ä¿¡åº¦å†…å®¹çš„å‡†ç¡®æ€§ï¼Œå¹¶è¡¥å……ä¿¡æ¯æ¥æºæ ‡æ³¨")

        return {"score": score, "issues": issues, "suggestions": suggestions}

    def _check_logical_coherence(self, slides_data: List[Dict], outline: Dict) -> Dict:
        """ç»´åº¦2: é€»è¾‘è¿è´¯æ€§æ£€æŸ¥"""
        issues = []
        suggestions = []
        score = 100

        # æ£€æŸ¥ç« èŠ‚ç»“æ„å®Œæ•´æ€§
        sections = outline.get("sections", [])
        if not sections:
            issues.append({
                "dimension": "logical_coherence",
                "severity": "critical",
                "message": "ç¼ºå°‘ç« èŠ‚ç»“æ„",
            })
            return {"score": 30, "issues": issues, "suggestions": ["éœ€è¦é‡æ–°è§„åˆ’å¤§çº²"]}

        # æ£€æŸ¥å°é¢å’Œç»“æŸé¡µ
        if slides_data:
            first_type = slides_data[0].get("content_type", "")
            if first_type != "cover":
                issues.append({
                    "dimension": "logical_coherence",
                    "severity": "warning",
                    "message": "ç¬¬ä¸€é¡µä¸æ˜¯å°é¢é¡µ",
                })
                score -= 5

            last_type = slides_data[-1].get("content_type", "")
            if last_type != "ending":
                issues.append({
                    "dimension": "logical_coherence",
                    "severity": "info",
                    "message": "æœ€åä¸€é¡µä¸æ˜¯ç»“æŸé¡µ",
                })
                score -= 3

        # ä½¿ç”¨LLMæ£€æŸ¥é€»è¾‘è¿è´¯æ€§
        if self.llm_client and slides_data:
            titles = [f"P{sd.get('page_num')}: {sd.get('title', '')}" for sd in slides_data]
            prompt = (
                "è¯·è¯„ä¼°ä»¥ä¸‹PPTé¡µé¢æ ‡é¢˜åºåˆ—çš„é€»è¾‘è¿è´¯æ€§ï¼ˆ0-100åˆ†ï¼‰ã€‚\n\n"
                f"é¡µé¢åºåˆ—:\n" + "\n".join(titles) + "\n\n"
                "è¯„ä¼°æ ‡å‡†:\n"
                "1. æ˜¯å¦æœ‰æ¸…æ™°çš„å™äº‹ä¸»çº¿\n"
                "2. ç« èŠ‚é—´è¿‡æ¸¡æ˜¯å¦è‡ªç„¶\n"
                "3. æ˜¯å¦å­˜åœ¨é€»è¾‘è·³è·ƒ\n"
                "4. ç»“æ„æ˜¯å¦å®Œæ•´ï¼ˆå¼€å¤´-å±•å¼€-æ”¶å°¾ï¼‰\n\n"
                "è¯·è¾“å‡ºJSON:\n"
                '{"score": 85, "issues": ["é—®é¢˜1"], "suggestions": ["å»ºè®®1"]}'
            )
            try:
                result = self.llm_client.call_llm(prompt, response_json=True)
                llm_score = result.get("score", 80)
                score = int((score + llm_score) / 2)
                for issue in result.get("issues", []):
                    issues.append({
                        "dimension": "logical_coherence",
                        "severity": "info",
                        "message": issue,
                    })
                suggestions.extend(result.get("suggestions", []))
            except Exception:
                pass

        score = max(0, min(100, score))
        return {"score": score, "issues": issues, "suggestions": suggestions}

    def _check_visual_compliance(self, slides_data: List[Dict],
                                  template_analysis: Dict) -> Dict:
        """ç»´åº¦3: è§†è§‰è§„èŒƒæ€§æ£€æŸ¥"""
        issues = []
        suggestions = []
        score = 100

        total_layouts = template_analysis.get("total_layouts", 1)

        for sd in slides_data:
            layout_idx = sd.get("layout_index", 0)
            if layout_idx < 0 or layout_idx >= total_layouts:
                issues.append({
                    "dimension": "visual_compliance",
                    "severity": "warning",
                    "page": sd.get("page_num"),
                    "message": f"ç¬¬{sd.get('page_num')}é¡µä½¿ç”¨äº†æ— æ•ˆçš„ç‰ˆå¼ç´¢å¼•({layout_idx})",
                })
                score -= 5

        # æ£€æŸ¥ç‰ˆå¼å¤šæ ·æ€§
        used_layouts = set(sd.get("layout_index", 0) for sd in slides_data)
        content_pages = [sd for sd in slides_data
                         if sd.get("content_type") not in ("cover", "ending", "section_divider")]
        if len(content_pages) > 5 and len(used_layouts) < 3:
            issues.append({
                "dimension": "visual_compliance",
                "severity": "info",
                "message": f"ç‰ˆå¼å¤šæ ·æ€§ä¸è¶³ï¼Œ{len(content_pages)}é¡µå†…å®¹ä»…ä½¿ç”¨äº†{len(used_layouts)}ç§ç‰ˆå¼",
            })
            suggestions.append("å»ºè®®å¢åŠ ç‰ˆå¼å¤šæ ·æ€§ï¼Œé¿å…è§†è§‰ç–²åŠ³")
            score -= 5

        # æ£€æŸ¥è¿ç»­é‡å¤ç‰ˆå¼
        prev_layout = None
        consecutive = 0
        for sd in slides_data:
            if sd.get("content_type") in ("cover", "ending", "section_divider"):
                prev_layout = None
                consecutive = 0
                continue
            curr_layout = sd.get("layout_index")
            if curr_layout == prev_layout:
                consecutive += 1
                if consecutive >= 3:
                    issues.append({
                        "dimension": "visual_compliance",
                        "severity": "info",
                        "page": sd.get("page_num"),
                        "message": f"ç¬¬{sd.get('page_num')}é¡µé™„è¿‘è¿ç»­{consecutive+1}é¡µä½¿ç”¨ç›¸åŒç‰ˆå¼",
                    })
                    score -= 3
            else:
                consecutive = 0
            prev_layout = curr_layout

        score = max(0, min(100, score))
        return {"score": score, "issues": issues, "suggestions": suggestions}

    def _check_information_density(self, slides_data: List[Dict]) -> Dict:
        """ç»´åº¦4: ä¿¡æ¯å¯†åº¦æ£€æŸ¥"""
        issues = []
        suggestions = []
        score = 100

        for sd in slides_data:
            if sd.get("content_type") in ("cover", "ending", "section_divider"):
                continue

            content = sd.get("content", {})
            body = content.get("body", [])
            page_num = sd.get("page_num")

            # æ£€æŸ¥è¿‡è½½
            if len(body) > 7:
                issues.append({
                    "dimension": "information_density",
                    "severity": "warning",
                    "page": page_num,
                    "message": f"ç¬¬{page_num}é¡µæœ‰{len(body)}ä¸ªè¦ç‚¹ï¼Œä¿¡æ¯è¿‡è½½",
                })
                score -= 5
                suggestions.append(f"å»ºè®®å°†ç¬¬{page_num}é¡µæ‹†åˆ†ä¸ºå¤šé¡µ")

            # æ£€æŸ¥ç©ºæ´
            if len(body) == 0:
                issues.append({
                    "dimension": "information_density",
                    "severity": "warning",
                    "page": page_num,
                    "message": f"ç¬¬{page_num}é¡µæ²¡æœ‰æ­£æ–‡å†…å®¹",
                })
                score -= 5

            # æ£€æŸ¥å•ä¸ªè¦ç‚¹è¿‡é•¿
            for i, item in enumerate(body):
                if len(str(item)) > 60:
                    issues.append({
                        "dimension": "information_density",
                        "severity": "info",
                        "page": page_num,
                        "message": f"ç¬¬{page_num}é¡µç¬¬{i+1}ä¸ªè¦ç‚¹è¿‡é•¿({len(str(item))}å­—)",
                    })
                    score -= 2

            # æ£€æŸ¥æ ‡é¢˜è¿‡é•¿
            title = content.get("title", "")
            if len(title) > 20:
                issues.append({
                    "dimension": "information_density",
                    "severity": "info",
                    "page": page_num,
                    "message": f"ç¬¬{page_num}é¡µæ ‡é¢˜è¿‡é•¿({len(title)}å­—)",
                })
                score -= 2

        score = max(0, min(100, score))
        return {"score": score, "issues": issues, "suggestions": suggestions}

    def _check_audience_fit(self, slides_data: List[Dict], config: Dict) -> Dict:
        """ç»´åº¦5: å—ä¼—é€‚é…æ€§æ£€æŸ¥"""
        issues = []
        suggestions = []
        score = 85  # é»˜è®¤åŸºç¡€åˆ†

        audience = config.get("audience", "")
        scenario = config.get("scenario", "")
        language_style = config.get("language_style", "")

        if not self.llm_client:
            return {"score": score, "issues": issues, "suggestions": suggestions}

        # æ”¶é›†æ‰€æœ‰å†…å®¹æ–‡æœ¬
        all_content = []
        for sd in slides_data:
            content = sd.get("content", {})
            all_content.append({
                "page": sd.get("page_num"),
                "title": content.get("title", ""),
                "body": content.get("body", [])[:3],
            })

        prompt = (
            "è¯·è¯„ä¼°ä»¥ä¸‹PPTå†…å®¹ä¸ç›®æ ‡å—ä¼—çš„é€‚é…åº¦ï¼ˆ0-100åˆ†ï¼‰ã€‚\n\n"
            f"ç›®æ ‡å—ä¼—: {audience or 'æœªæŒ‡å®š'}\n"
            f"æ±‡æŠ¥åœºæ™¯: {scenario or 'æœªæŒ‡å®š'}\n"
            f"æœŸæœ›è¯­è¨€é£æ ¼: {language_style or 'æœªæŒ‡å®š'}\n\n"
            f"PPTå†…å®¹æ‘˜è¦:\n{json.dumps(all_content[:10], ensure_ascii=False)}\n\n"
            "è¯„ä¼°æ ‡å‡†:\n"
            "1. è¯­è¨€ä¸“ä¸šåº¦æ˜¯å¦åŒ¹é…å—ä¼—\n"
            "2. å†…å®¹æ·±åº¦æ˜¯å¦åˆé€‚\n"
            "3. é‡ç‚¹æ˜¯å¦å¯¹å‡†å—ä¼—å…³æ³¨ç‚¹\n"
            "4. æœ¯è¯­ä½¿ç”¨æ˜¯å¦æ°å½“\n\n"
            "è¯·è¾“å‡ºJSON:\n"
            '{"score": 85, "issues": ["é—®é¢˜1"], "suggestions": ["å»ºè®®1"]}'
        )

        try:
            result = self.llm_client.call_llm(prompt, response_json=True)
            score = result.get("score", 85)
            for issue in result.get("issues", []):
                issues.append({
                    "dimension": "audience_fit",
                    "severity": "info",
                    "message": issue,
                })
            suggestions.extend(result.get("suggestions", []))
        except Exception:
            pass

        score = max(0, min(100, score))
        return {"score": score, "issues": issues, "suggestions": suggestions}

    def _generate_review_summary(self, overall_score: int, dimension_scores: Dict,
                                  issues: List[Dict], suggestions: List[Dict],
                                  config: Dict) -> str:
        """ç”Ÿæˆç»¼åˆè¯„å®¡æ„è§"""
        if self.llm_client:
            prompt = (
                "è¯·æ ¹æ®ä»¥ä¸‹è¯„å®¡ç»“æœï¼Œç”Ÿæˆä¸€æ®µç®€æ´çš„ç»¼åˆè¯„å®¡æ„è§ï¼ˆ3-5å¥è¯ï¼‰ã€‚\n\n"
                f"æ€»åˆ†: {overall_score}/100\n"
                f"å„ç»´åº¦å¾—åˆ†:\n"
            )
            for k, v in dimension_scores.items():
                prompt += f"  - {k}: {v.get('score', 0)}/100\n"
            prompt += f"\nä¸»è¦é—®é¢˜: {json.dumps([i['message'] for i in issues[:5]], ensure_ascii=False)}\n"
            prompt += f"æ”¹è¿›å»ºè®®: {json.dumps(suggestions[:5], ensure_ascii=False)}\n"
            prompt += "\nè¯·ç›´æ¥è¾“å‡ºè¯„å®¡æ„è§æ–‡æœ¬ï¼Œä¸è¦JSONæ ¼å¼ã€‚"

            try:
                return self.llm_client.call_llm(prompt, temperature=0.3)
            except Exception:
                pass

        # å…œåº•
        level = "ä¼˜ç§€" if overall_score >= 90 else "è‰¯å¥½" if overall_score >= 80 else "åˆæ ¼" if overall_score >= 70 else "éœ€æ”¹è¿›"
        return f"ç»¼åˆè¯„åˆ†: {overall_score}/100 ({level})ã€‚å…±å‘ç°{len(issues)}ä¸ªé—®é¢˜ï¼Œ{len(suggestions)}æ¡æ”¹è¿›å»ºè®®ã€‚"

    def format_review_output(self, review_result: Dict) -> str:
        """æ ¼å¼åŒ–è¯„å®¡ç»“æœä¾›ç”¨æˆ·æŸ¥çœ‹"""
        lines = []
        overall = review_result.get("overall_score", 0)
        passed = review_result.get("passed", False)

        # æ€»åˆ†
        level_icon = "ğŸŸ¢" if overall >= 80 else "ğŸŸ¡" if overall >= 70 else "ğŸ”´"
        lines.append(f"## {level_icon} è´¨é‡è¯„å®¡æŠ¥å‘Š\n")
        lines.append(f"**æ€»åˆ†: {overall}/100** {'âœ… é€šè¿‡' if passed else 'âŒ éœ€æ”¹è¿›'}\n")

        # äº”ç»´åº¦é›·è¾¾
        lines.append("### ğŸ“Š äº”ç»´åº¦è¯„åˆ†\n")
        dims = review_result.get("dimension_scores", {})
        dim_labels = {
            "content_accuracy": "å†…å®¹å‡†ç¡®æ€§",
            "logical_coherence": "é€»è¾‘è¿è´¯æ€§",
            "visual_compliance": "è§†è§‰è§„èŒƒæ€§",
            "information_density": "ä¿¡æ¯å¯†åº¦",
            "audience_fit": "å—ä¼—é€‚é…æ€§",
        }
        for key, label in dim_labels.items():
            dim = dims.get(key, {})
            s = dim.get("score", 0)
            bar = "â–ˆ" * (s // 10) + "â–‘" * (10 - s // 10)
            lines.append(f"  {label}: {bar} {s}/100")
        lines.append("")

        # ç»¼åˆè¯„å®¡æ„è§
        summary = review_result.get("summary", "")
        if summary:
            lines.append(f"### ğŸ’¬ ç»¼åˆè¯„å®¡æ„è§\n")
            lines.append(f"> {summary}\n")

        # é—®é¢˜åˆ—è¡¨
        issues = review_result.get("issues", [])
        if issues:
            critical = [i for i in issues if i.get("severity") == "critical"]
            warnings = [i for i in issues if i.get("severity") == "warning"]
            infos = [i for i in issues if i.get("severity") == "info"]

            if critical:
                lines.append("### ğŸ”´ ä¸¥é‡é—®é¢˜\n")
                for i in critical:
                    page_info = f"(P{i['page']})" if i.get("page") else ""
                    lines.append(f"  - {i['message']} {page_info}")
                lines.append("")

            if warnings:
                lines.append("### ğŸŸ¡ è­¦å‘Š\n")
                for i in warnings:
                    page_info = f"(P{i['page']})" if i.get("page") else ""
                    lines.append(f"  - {i['message']} {page_info}")
                lines.append("")

            if infos:
                lines.append("### ğŸ”µ å»ºè®®\n")
                for i in infos[:5]:
                    page_info = f"(P{i['page']})" if i.get("page") else ""
                    lines.append(f"  - {i['message']} {page_info}")
                if len(infos) > 5:
                    lines.append(f"  ... è¿˜æœ‰ {len(infos) - 5} æ¡å»ºè®®")
                lines.append("")

        # æ”¹è¿›å»ºè®®
        suggestions = review_result.get("suggestions", [])
        if suggestions:
            lines.append("### ğŸ’¡ æ”¹è¿›å»ºè®®\n")
            for s in suggestions[:5]:
                lines.append(f"  - {s}")
            lines.append("")

        return "\n".join(lines)
