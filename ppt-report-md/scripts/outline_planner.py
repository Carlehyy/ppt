#!/usr/bin/env python3
"""
å¤§çº²è§„åˆ’æ¨¡å— â€” åŸºäºå†…å®¹åˆ†æè®¾è®¡æ±‡æŠ¥å¤§çº²
"""

import json
from typing import Dict, Any
from llm_client import LLMClient
from utils import load_prompt


class OutlinePlanner:
    """å¤§çº²è§„åˆ’å™¨"""

    def __init__(self, llm: LLMClient):
        self.llm = llm

    def plan(self, parsed_content: Dict[str, Any], user_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ±‡æŠ¥å¤§çº²

        Args:
            parsed_content: å†…å®¹è§£æç»“æœ
            user_config: ç”¨æˆ·é…ç½®

        Returns:
            å¤§çº²è§„åˆ’ç»“æœ
        """
        print("ğŸ“‹ å¼€å§‹è§„åˆ’æ±‡æŠ¥å¤§çº²...")

        # å‡†å¤‡ç”¨æˆ·é…ç½®
        config_str = self._format_user_config(user_config)

        # å‡†å¤‡å†…å®¹åˆ†ææ‘˜è¦
        content_str = json.dumps(parsed_content, ensure_ascii=False, indent=2)

        # è°ƒç”¨LLMç”Ÿæˆå¤§çº²
        prompt = load_prompt(
            "outline_planning",
            content_analysis=content_str,
            user_config=config_str
        )

        outline_result = self.llm.call_llm(prompt, response_json=True)

        print("âœ… å¤§çº²è§„åˆ’å®Œæˆ\n")
        return outline_result

    def _format_user_config(self, user_config: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·é…ç½®ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
        config_lines = []
        config_lines.append(f"æ±‡æŠ¥æ ‡é¢˜: {user_config.get('presentation_title', 'æœªæŒ‡å®š')}")
        config_lines.append(f"æ±‡æŠ¥åœºæ™¯: {user_config.get('scenario', 'å‘ä¸Šæ±‡æŠ¥')}")
        config_lines.append(f"æ ¸å¿ƒè¯‰æ±‚: {user_config.get('core_intent', 'æœªæŒ‡å®š')}")
        config_lines.append(f"ç›®æ ‡é¡µæ•°: {user_config.get('target_pages', 15)}é¡µ")
        config_lines.append(f"è¯­è¨€é£æ ¼: {user_config.get('language_style', 'ä¸“ä¸šç®€æ´')}")
        return "\n".join(config_lines)
